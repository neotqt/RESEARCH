{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#fff200'> **Notebook Purpose and Introduction**\n",
        "\n",
        "### **Purpose**\n",
        "To clearly outline the three criteria that will be referenced throughout this paper.\n",
        "\n",
        "### **Introduction**\n",
        "Having predefined criteria allows for standardization in evaluating the quality and meaningfulness of music pieces in general. Below are the three criteria I have chosen.\n",
        "\n",
        "**Criteria 1 ~ Tonality**: Tonality refers to the organization of pitches and harmonies around a central note, known as the tonic. In meaningful music, intentional tonality indicates a deliberate choice and adherence to a specific tonal center throughout the composition. This criterion assesses whether the music maintains a coherent tonal structure, such as major or minor keys, which can provide a sense of stability, direction, and emotional resonance to the listener.\n",
        "\n",
        "**Criteria 2 ~ Meter**: Meter refers to the rhythmic framework or pulse that organizes musical patterns into regular beats or measures. In meaningful music, meter plays a crucial role in establishing rhythmic stability and providing a sense of groove or flow. This criterion evaluates whether the music maintains a consistent meter, such as 4/4 time or waltz time, and effectively utilizes rhythmic patterns to convey musical structure and coherence.\n",
        "\n",
        "**Criteria 3 ~ Melodic Structure**: Melodic structure refers to how individual pitches are organized over time to form a coherent and memorable melody. It includes the shape of the melody (pitch contour), the distances between pitches (intervallic relationships), the rhythmic patterns, the division into musical phrases (phrasing), and the development of recurring motifs (motivic development)."
      ],
      "metadata": {
        "id": "BDR_kgIv8u5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Necessary Libraries and Installations**"
      ],
      "metadata": {
        "id": "5nioysPfNPcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mido"
      ],
      "metadata": {
        "id": "kkb4bJslUl2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install midi2audio"
      ],
      "metadata": {
        "id": "P201txUeWzJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "XgA-aYeUW0YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install fluidsynth"
      ],
      "metadata": {
        "id": "MWGF009RW2mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7xqAeo8Ybos"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import mido\n",
        "import soundfile as sf\n",
        "\n",
        "from librosa import midi_to_hz\n",
        "from midi2audio import FluidSynth\n",
        "from mido import MidiFile, MidiTrack, tempo2bpm\n",
        "from pydub import AudioSegment\n",
        "from fractions import Fraction\n",
        "from scipy.signal import find_peaks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "EX9g44_6W4Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IiOOAp7HdQ_"
      },
      "source": [
        "# **Criteria 1 - Tonality**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQf7FJ6Fy6zu"
      },
      "source": [
        "**Running Pitch Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monophonicDirectory = \"/content/drive/Shareddrives/neotyagi-dataset/nottingham-dataset-master/MIDI/NottinghamTest/[3] Pitch Test\"\n",
        "noteInTuneTolerance = 7\n",
        "pieceInTuneThreshold = 85\n",
        "\n",
        "noteFrequencies = [\n",
        "    65.41, 69.30, 73.42, 77.78, 82.41, 87.31, 92.50, 98.00, 103.83, 110.00, 116.54,\n",
        "    123.47, 130.81, 138.59, 146.83, 155.56, 164.81, 174.61, 185.00, 196.00, 207.65,\n",
        "    220.00, 233.08, 246.94, 261.63, 277.18, 293.66, 311.13, 329.63, 349.23, 369.99,\n",
        "    392.00, 415.30, 440.00, 466.16, 493.88, 523.25, 554.37, 587.33, 622.25, 659.26,\n",
        "    698.46, 739.99, 783.99, 830.61, 880.00, 932.33, 987.77, 1046.50, 1108.73, 1174.66,\n",
        "    1244.51, 1318.51, 1396.91, 1479.98, 1567.98, 1661.22, 1760.00, 1864.66, 1975.53\n",
        "]\n",
        "\n",
        "def findClosestNoteFrequency(frequency):\n",
        "    return min(noteFrequencies, key = lambda x: abs(x - frequency))\n",
        "\n",
        "for filename in os.listdir(monophonicDirectory):\n",
        "    totalNotes = 0\n",
        "    if filename.endswith(\"TRUNCATED.mid\"):\n",
        "        filepath = os.path.join(monophonicDirectory, filename)\n",
        "        filepathWAV = filepath[:-4] + '.wav'\n",
        "        fs = FluidSynth()\n",
        "        fs.midi_to_audio(filepath, filepathWAV)\n",
        "        audioData, sampleRate = librosa.load(filepathWAV, sr=None)\n",
        "        inTuneCount = 0\n",
        "\n",
        "        frequencyEstimatesPYIN = librosa.pyin(audioData, fmin = librosa.note_to_hz('C2'), fmax = librosa.note_to_hz('C7'), fill_na = -1)\n",
        "        frequencies = frequencyEstimatesPYIN[0]\n",
        "        magnitudes = frequencyEstimatesPYIN[1]\n",
        "\n",
        "\n",
        "        for i in range(0, len(frequencies), 5):\n",
        "          frequency = frequencies[i]\n",
        "          if frequency > 0:\n",
        "            # print(f\"This is the Frequency by PYIN: {frequency:.2f} Hz\")\n",
        "            closestNoteFrequency = findClosestNoteFrequency(frequency)\n",
        "            # print(f\"This is the closestNoteFrequency: {closestNoteFrequency:.2f} Hz\")\n",
        "\n",
        "            if abs(frequency - closestNoteFrequency) <= noteInTuneTolerance:\n",
        "                inTuneCount += 1\n",
        "            totalNotes+=1\n",
        "\n",
        "        percentageInTune = (inTuneCount / totalNotes) * 100\n",
        "        isPieceInTune = percentageInTune >= pieceInTuneThreshold\n",
        "\n",
        "        print(\"\")\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Percentage of in-tune notes: {percentageInTune}%\")\n",
        "        print(f\"The piece is{' ' if isPieceInTune else ' not '}in tune.\\n\")"
      ],
      "metadata": {
        "id": "cdi-7Df0wAOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYzX62vECWx"
      },
      "source": [
        "# **Criteria 2 - Meter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMg1U7GQEIU4"
      },
      "source": [
        "**Running Beat Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testDirectoryMeter = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/[4] Meter Test\"\n",
        "\n",
        "# This function checks if a piece has randomly distributed notes.\n",
        "def hasRandomNotes(audioFile, maxStabilityThreshold = 0.07, maxNoteRepetitions = 5, maxNoteDistributionStability = 14):\n",
        "    audioData, sampleRate = librosa.load(audioFile)\n",
        "\n",
        "    cqt = librosa.cqt(y = audioData, sr = sampleRate) # Calculate the constant-Q chromagram [a representation of an audio signal that captures the energy distribution of different pitches over time].\n",
        "    chromagram = librosa.amplitude_to_db(np.abs(cqt), ref=np.max) # Convert to decibels for easier analysis.\n",
        "\n",
        "    # Calculating the note distribution stability\n",
        "    noteDistributionStability = np.std(chromagram, axis=0).mean()\n",
        "\n",
        "    onsetStrength = librosa.onset.onset_strength(y = audioData, sr = sampleRate) # Onset Strength: The magnitude of sudden changes in the audio signal [beginning of a note].\n",
        "    tempo, _ = librosa.beat.beat_track(onset_envelope = onsetStrength, sr = sampleRate)\n",
        "    _, beatTimes = librosa.beat.beat_track(onset_envelope = onsetStrength, sr = sampleRate, units = 'time') # Estimating the tempo and the beat times.\n",
        "\n",
        "    meanTempoInterval = np.mean(np.diff(beatTimes))\n",
        "    meanTempoIntervalStandardDeviation = np.std(np.diff(beatTimes))\n",
        "    rhythmicStability = meanTempoIntervalStandardDeviation / meanTempoInterval\n",
        "\n",
        "    noteOnsets = librosa.onset.onset_detect(y = audioData, sr = sampleRate) # Detects the beginning of notes and calculating the maximum note repetitions in the audio.\n",
        "    noteIntervals = np.diff(noteOnsets)\n",
        "    maxNoteReps = np.max(np.bincount(noteIntervals))\n",
        "\n",
        "    if rhythmicStability >= maxStabilityThreshold or noteDistributionStability >= maxNoteDistributionStability or maxNoteReps >= maxNoteRepititions:\n",
        "        return True, rhythmicStability, noteDistributionStability, maxNoteReps\n",
        "    else:\n",
        "        return False, rhythmicStability, noteDistributionStability, maxNoteReps\n",
        "\n",
        "for filename in os.listdir(testDirectoryMeter):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(testDirectoryMeter, filename)\n",
        "        # filepathWAV = filepath[:-4] + '.wav'\n",
        "        # fs = FluidSynth()\n",
        "        # fs.midi_to_audio(filepath, filepath)\n",
        "        hasRandom, rhythmStability, noteDistributionStability, maxNoteRepititions = hasRandomNotes(filepath)\n",
        "        if hasRandom:\n",
        "            print(f\"{filename}: The piece has randomly distributed notes.\")\n",
        "        else:\n",
        "            print(f\"{filename}: The piece has a good rhythm with structured note distribution.\")\n",
        "        print(f\"Rhythmic Stability: {rhythmStability:.2f}\")                     # A lower value of rhythmic stability indicates more stable rhythm patterns | higher = less stable rhythm patterns.\n",
        "        print(f\"Note Distribution Stability: {noteDistributionStability:.2f}\")  # A lower value of note distribution stability indicates even distribution across the pitch range | higher = less even distribution\n",
        "        print(f\"Maximum Note Repititons: {maxNoteRepititions:.2f}\")"
      ],
      "metadata": {
        "id": "OcHGNe8DKDTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yeJchmmB4Kn"
      },
      "source": [
        "# **Criteria 3 - Melodic Structure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLwV6ckCY6B"
      },
      "source": [
        "**Running Melodic Structure Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testDirectoryMelody = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/[6] Melodic Structure Test\"\n",
        "\n",
        "# Function to analyze melodic structure\n",
        "def analyzeMelodicStructure(audioFile):\n",
        "    audioData, samplingRate = librosa.load(audioFile)\n",
        "\n",
        "    pitches, magnitudes = librosa.core.piptrack(y = audioData, sr = samplingRate) # Compute the pitch (fundamental frequency - lowest frequency) over time\n",
        "\n",
        "    pitchContour = pitches[np.argmax(magnitudes, axis=0)]\n",
        "    pitchContour = pitchContour.ravel()  # Flatten to a 1D Array.\n",
        "\n",
        "    melodicIntervals = np.diff(pitchContour)                                    # Melodic intervals are the differences between consecutive pitch values.\n",
        "    melodicPeaks, _ = find_peaks(pitchContour)\n",
        "    melodicComplexity = np.std(melodicIntervals)                                # Measures the standard deviation of the intervals between consecutive pitches in the melodic contour.\n",
        "\n",
        "\n",
        "    melodicStabilityRange = np.max(pitchContour) - np.min(pitchContour)         # Measures the span between the highest and lowest pitches in the melodic contour.\n",
        "    noteDurations = np.diff(melodicPeaks) / samplingRate\n",
        "    dynamicVariation = np.std(audioData)\n",
        "\n",
        "    return melodicPeaks, melodicComplexity, melodicStabilityRange, noteDurations, dynamicVariation\n",
        "\n",
        "for filename in os.listdir(testDirectoryMelody):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(testDirectoryMelody, filename)\n",
        "        melodicPeaks, melodicComplexity, melodicStabilityRange, noteDurations, dynamicVariation = analyzeMelodicStructure(filepath)  # Analyze melodic structure\n",
        "\n",
        "        print(f'File: {filename}\\n')\n",
        "\n",
        "        print(f'Melodic Peaks: {melodicPeaks}')                                 # Peaks in the pitch contour can indicate potential melodic peaks or points of repetition.\n",
        "\n",
        "\n",
        "        print(f'\\nMelodic Complexity: {melodicComplexity}')                     # A higher melodic complexity indicates greater variation in the intervals between consecutive pitches.\n",
        "                                                                                # This could suggest a more intricate and diverse melodic structure with complex patterns and variations.\n",
        "\n",
        "                                                                                # A lower melodic complexity suggests more consistent intervals between pitches.\n",
        "                                                                                # This could indicate a simpler or more repetitive melodic structure with less variation in pitch intervals.\n",
        "\n",
        "        print(f'\\nMelodic Stability: {melodicStabilityRange}')                  # A larger melodic stability range suggests a wider pitch range in the melody, indicating a more diverse or expansive melodic structure.\n",
        "                                                                                # A smaller melodic stability range suggests a more focused or narrow pitch range, possibly indicating a simpler or repetitive melodic structure.\n",
        "\n",
        "        print(f'\\nAverage Note Duration: {np.mean(noteDurations):.4f} seconds') # A higher average note duration indicates that the notes in the melody are sustained for a longer time. This might suggest a slower-paced melodic style.\n",
        "                                                                                # A lower average note duration suggests shorter note durations on average, which might indicate a faster-paced or more staccato melodic style.\n",
        "\n",
        "        print(f'\\nStandard Deviation of Note Duration: {np.std(noteDurations):.4f} seconds') # A higher standard deviation of note duration indicates greater variability in the duration of notes. This suggests a more dynamic melody.\n",
        "                                                                                # A lower standard deviation suggests more consistent note durations, indicating a more regular and predictable rhythm.\n",
        "\n",
        "        print(f'\\nDynamic Variation: {dynamicVariation}')                       # A higher dynamic variation suggests a wider range of loudness levels in the melody. This might indicate a more expressive and dynamically varied performance.\n",
        "                                                                                # A lower dynamic variation suggests a more consistent loudness level, which might indicate a more controlled or uniform performance.\n",
        "        print()\n",
        "        print('=' * 50)\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "QtaBip1MiS52"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}