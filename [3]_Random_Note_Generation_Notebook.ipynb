{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#fff200'> **Notebook Purpose and Introduction**\n",
        "\n",
        "### **Purpose**\n",
        "To test the rigor of the three previously defined criteria.\n",
        "\n",
        "### **Introduction**\n",
        "By including pieces of music with random notes, I establish a baseline for comparison. These pieces lack intentional tonality, coherent meter, and meaningful melodic structure. Contrasting them with music that adheres to these criteria helps highlight the importance of intentional tonality, meter, and melodic structure in creating meaningful music."
      ],
      "metadata": {
        "id": "9Q6jlRvTRdfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Necessary Libraries and Installations**"
      ],
      "metadata": {
        "id": "BDR_kgIv8u5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mido"
      ],
      "metadata": {
        "id": "kkb4bJslUl2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install midi2audio"
      ],
      "metadata": {
        "id": "P201txUeWzJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "XgA-aYeUW0YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install fluidsynth"
      ],
      "metadata": {
        "id": "MWGF009RW2mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7xqAeo8Ybos"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import music21\n",
        "import mido\n",
        "import soundfile as sf\n",
        "import subprocess\n",
        "\n",
        "from librosa import midi_to_hz\n",
        "from midi2audio import FluidSynth\n",
        "from mido import MidiFile, MidiTrack, tempo2bpm\n",
        "from pydub import AudioSegment\n",
        "from music21 import converter, stream, meter\n",
        "from fractions import Fraction\n",
        "from scipy.signal import find_peaks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "EX9g44_6W4Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3sg1oKrU0fA"
      },
      "source": [
        "# **Random Music Generation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/Shareddrives/neotyagi-dataset\n",
        "!git clone https://github.com/kevinzhang96/random-notes.git"
      ],
      "metadata": {
        "id": "Y5R75FGNWbMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Version Usage: !python filepath # iterations\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "# Original Repository: https://github.com/kevinzhang96/random-notes\n",
        "# Edited By: Neo Tyagi\n",
        "# Date: December 18th, 2023\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "# Original Author's Note:\n",
        "\n",
        "# lots of code used from other sites; not all my own work!\n",
        "# Some code from http://stackoverflow.com/a/311634/2605023 and\n",
        "# http://soledadpenades.com/2009/10/29/fastest-way-to-generate-wav-files-in-python-using-the-wave-module/\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "import sys, os\n",
        "import random\n",
        "import struct, re\n",
        "import numpy\n",
        "import wave\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "FPS = 44100                                                                     # the original number of frames per second in a wave file\n",
        "\n",
        "WAVSECONDS = int(sys.argv[1])                                                   # the number of seconds in the wav\n",
        "WAVLENGTH  = WAVSECONDS * FPS                                                   # the number of frames in the wav\n",
        "\n",
        "CURRENTDIR = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/[5] Garbage Music Generation\"                                                         # the current directory\n",
        "WAVDIR     = CURRENTDIR                                                         # the wav file directory\n",
        "DIRFILES   = [filename for filename in os.listdir(WAVDIR) if os.path.isfile(WAVDIR + filename)] # filter for files only\n",
        "WAVPATTERN = re.compile('^randomwav\\d{3}.wav')\n",
        "WAVFILES   = [file for file in DIRFILES if WAVPATTERN.match(file)]              # filter for wav files formatted as 'randomwav###.wav'\n",
        "WAVFILES.sort()                                                                 # sort by number; not necessary right now\n",
        "WAVFILECOUNT = len(WAVFILES)                                                    # number of existing wavs\n",
        "\n",
        "minFrequency = 100\n",
        "maxFrequency = 6000\n",
        "\n",
        "if WAVFILECOUNT > 1000:\n",
        "  print ('Please clear your /wavs directory before continuing.')                # just for cleanliness\n",
        "else:\n",
        "    NewNumber = str(WAVFILECOUNT).zfill(3)                                      # next wav's index\n",
        "    FileName  = WAVDIR + 'randomwav' + NewNumber + '.wav'                       # the wav's filename\n",
        "    output = wave.open(FileName, 'w')                                           # create the wav\n",
        "    output.setparams((2, 2, 44100, 0, 'NONE', 'not compressed'))                # set the wav file's properties\n",
        "\n",
        "    value_str = b''                                                             # this will contain the frames we write\n",
        "\n",
        "    if random.choice([True, False]):\n",
        "      print(\"This piece is monophonic\\n\\n\")\n",
        "      for i in range(0, WAVSECONDS):\n",
        "        baseNoteRate = random.uniform(2, 8)                                     # for each note to be played\n",
        "        noteLengthFactor = random.uniform(0.6, 1.4)\n",
        "        newNoteRate = baseNoteRate * noteLengthFactor\n",
        "        value = random.choice(FREQARRAY)                                        # pick a random frequency\n",
        "        print(\"Value chosen: \", value)\n",
        "\n",
        "        if random.choice([True, False]):\n",
        "          tempoChange = random.uniform(-0.5, 0.5)\n",
        "          newNoteRate *= 1 + tempoChange\n",
        "\n",
        "        print(\"newNoteRate: \", newNoteRate)\n",
        "        period = float(FPS / newNoteRate) / float(value)                        # calculate the period\n",
        "        omega = numpy.pi * 2 / period                                           # and the omega\n",
        "        xaxis = numpy.arange(int(period), dtype = float) * omega                # get the x-value\n",
        "        ydata = 16384 * numpy.sin(xaxis)                                        # create a sin-wave\n",
        "\n",
        "        signal = numpy.resize(ydata, int(WAVLENGTH / baseNoteRate))             # resize the sin-wave\n",
        "        # print(\"Signal Array: \", signal)\n",
        "\n",
        "        ssignal = b''                                                           # temporary holding value\n",
        "\n",
        "        for j in range(len(signal)):                                            # write the sin-wave to a string\n",
        "          ssignal += struct.pack('h', int(signal[j]))\n",
        "        value_str += ssignal                                                    # append the string to the total\n",
        "    else:\n",
        "      PCM_SCALE = 32767.0\n",
        "      signal = numpy.zeros(int(WAVLENGTH))\n",
        "      for i in range(0, WAVSECONDS):\n",
        "        FREQARRAY = [random.uniform(minFrequency, maxFrequency) for _ in range(6000)]\n",
        "        numNotesPerWAVSec = random.randint(2, 5)\n",
        "        notesInWAVSecond = []\n",
        "        maxNoteLength = 0\n",
        "\n",
        "        for _ in range(numNotesPerWAVSec):\n",
        "          baseNoteRate = random.uniform(2, 8)                                     # for each note to be played\n",
        "          noteLengthRandomFactor = random.uniform(0.8, 1.2)\n",
        "          newNoteRate = baseNoteRate * noteLengthRandomFactor\n",
        "          if random.choice([True, False]):\n",
        "            tempoChange = random.uniform(-0.6, 0.6)\n",
        "            newNoteRate *= 1 + tempoChange\n",
        "          if i == 0:\n",
        "              note = {\n",
        "              'frequency': random.choice(FREQARRAY) * random.uniform(0.90,1.35),\n",
        "              'start': 0,\n",
        "              'length': int(newNoteRate * FPS)\n",
        "              }\n",
        "          else:\n",
        "            note = {\n",
        "              'frequency': random.choice(FREQARRAY) * random.uniform(0.85,1.35),\n",
        "              'start': maxNoteLength * random.uniform(0.15, 0.85),\n",
        "              'length': int(newNoteRate * FPS)\n",
        "            }\n",
        "          notesInWAVSecond.append(note)\n",
        "          maxNoteLength = max(maxNoteLength, note['length'])\n",
        "\n",
        "        for note in notesInWAVSecond:\n",
        "          NOTERATE = note['length'] / FPS\n",
        "          period = float(FPS / NOTERATE) / float(note['frequency'])\n",
        "          omega = numpy.pi * 2 / period\n",
        "          xaxis = numpy.arange(int(period), dtype = float) * omega\n",
        "          ydata = 16384 * numpy.sin(xaxis)\n",
        "\n",
        "          startIndex = int(note['start'] + i * FPS)\n",
        "          endIndex = int(startIndex + note['length'])\n",
        "          print(f\"Note Frequency: {note['frequency']} Hz\")\n",
        "          print(f\"Start Index: {startIndex}\")\n",
        "          print(f\"End Index: {endIndex}\")\n",
        "          print(f\"Note Length: {note['length'] / FPS} seconds\")\n",
        "          print()\n",
        "\n",
        "          ydata = numpy.resize(ydata, endIndex - startIndex)\n",
        "\n",
        "          signal = numpy.resize(signal, max(endIndex, len(signal)))\n",
        "          signal[slice(startIndex, endIndex)] += ydata                            # Accumulate the signal for each note\n",
        "\n",
        "        signal /= numpy.max(numpy.abs(signal)) / PCM_SCALE\n",
        "        print(\"\\nFirst 10 Elements of Signal Array:\", signal[:10])\n",
        "        print(\"\\nLast 10 Elements of Signal Array:\", signal[-10:])\n",
        "        print()\n",
        "        print(\"=\" * 100)\n",
        "        print()\n",
        "        ssignal = b''\n",
        "\n",
        "        for j in range(len(signal)):\n",
        "          ssignal += struct.pack('h', int(signal[j]))\n",
        "        value_str += ssignal\n",
        "\n",
        "    print()\n",
        "    print(\"\\nFirst Hundred Elements of Final Signal Array:\", signal[:100])\n",
        "    print(\"\\nLast Hundred Elements of Final Signal Array:\", signal[-100:])\n",
        "    print()\n",
        "    print('=' * 100)\n",
        "    print()\n",
        "    output.writeframes(value_str)                                               # write the frames to the wav\n",
        "    output.close()                                                              # finished making wav\n",
        "\n",
        "    if os.name == 'nt':                                                         # if on windows\n",
        "        import winsound\n",
        "        winsound.PlaySound(FileName, winsound.SND_FILENAME)                     # play using winsound\n",
        "    elif os.name == 'posix':                                                    # else if on linux\n",
        "        from pydub import AudioSegment\n",
        "        from pydub.playback import play\n",
        "        audio = AudioSegment.from_wav(FileName)\n",
        "        play(audio)\n",
        "\n",
        "    else:\n",
        "        import ossaudiodev                                                      # else on UNIX\n",
        "        s = wave.open(FileName, 'rb')                                           # play using ossaudio\n",
        "        (nc, sw, fr, nf, comptype, compname) = s.getparams()\n",
        "        dsp = ossaudiodev.open('/dev/dsp', 'w')\n",
        "        try:\n",
        "            from ossaudiodev import AFMT_S16_NE\n",
        "        except ImportError:\n",
        "            from sys import byteorder\n",
        "            if byteorder == 'little':\n",
        "                AFMT_S16_NE = ossaudiodev.AFMT_S16_LE\n",
        "            else:\n",
        "                AFMT_S16_NE = ossaudiodev.AFMT_S16_BE\n",
        "        dsp.setparameters(AFMT_S16_NE, nc, fr)\n",
        "        data = s.readframes(nf)\n",
        "        s.close()\n",
        "        dsp.write(data)\n",
        "        dsp.close()"
      ],
      "metadata": {
        "id": "F0rNQrt-OxEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/Shareddrives/neotyagi-dataset/random-notes/generatemono.py 15"
      ],
      "metadata": {
        "id": "SYv3oMxoVfBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/Shareddrives/neotyagi-dataset/random-notes/generatepoly.py 5"
      ],
      "metadata": {
        "id": "6zckDNfaJqCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IiOOAp7HdQ_"
      },
      "source": [
        "# **Criteria 1 - Tonality**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQf7FJ6Fy6zu"
      },
      "source": [
        "**Running Pitch Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monophonicDirectory = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/\"\n",
        "noteInTuneTolerance = 7\n",
        "pieceInTuneThreshold = 85\n",
        "\n",
        "noteFrequencies = [\n",
        "    65.41, 69.30, 73.42, 77.78, 82.41, 87.31, 92.50, 98.00, 103.83, 110.00, 116.54,\n",
        "    123.47, 130.81, 138.59, 146.83, 155.56, 164.81, 174.61, 185.00, 196.00, 207.65,\n",
        "    220.00, 233.08, 246.94, 261.63, 277.18, 293.66, 311.13, 329.63, 349.23, 369.99,\n",
        "    392.00, 415.30, 440.00, 466.16, 493.88, 523.25, 554.37, 587.33, 622.25, 659.26,\n",
        "    698.46, 739.99, 783.99, 830.61, 880.00, 932.33, 987.77, 1046.50, 1108.73, 1174.66,\n",
        "    1244.51, 1318.51, 1396.91, 1479.98, 1567.98, 1661.22, 1760.00, 1864.66, 1975.53\n",
        "]\n",
        "\n",
        "def findClosestNoteFrequency(frequency):\n",
        "    return min(noteFrequencies, key = lambda x: abs(x - frequency))\n",
        "\n",
        "for filename in os.listdir(monophonicDirectory):\n",
        "    totalNotes = 0\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(monophonicDirectory, filename)\n",
        "        # filepathWAV = filepath[:-4] + '.wav'\n",
        "        # fs = FluidSynth()\n",
        "        # fs.midi_to_audio(filepath, filepath)\n",
        "        audioData, sampleRate = librosa.load(filepath, sr=None)\n",
        "        inTuneCount = 0\n",
        "\n",
        "        frequencyEstimatesPYIN = librosa.pyin(audioData, fmin = librosa.note_to_hz('C2'), fmax = librosa.note_to_hz('C7'), fill_na = -1)\n",
        "        frequencies = frequencyEstimatesPYIN[0]\n",
        "        magnitudes = frequencyEstimatesPYIN[1]\n",
        "\n",
        "        for i in range(0, len(frequencies), 5):\n",
        "          frequency = frequencies[i]\n",
        "          if frequency > 0:\n",
        "            # print(f\"This is the Frequency by PYIN: {frequency:.2f} Hz\")\n",
        "            closestNoteFrequency = findClosestNoteFrequency(frequency)\n",
        "            # print(f\"This is the closestNoteFrequency: {closestNoteFrequency:.2f} Hz\")\n",
        "\n",
        "            if abs(frequency - closestNoteFrequency) <= noteInTuneTolerance:\n",
        "                inTuneCount += 1\n",
        "            totalNotes+=1\n",
        "\n",
        "        percentageInTune = (inTuneCount / totalNotes) * 100\n",
        "        isPieceInTune = percentageInTune >= pieceInTuneThreshold\n",
        "\n",
        "        print(\"\")\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Percentage of in-tune notes: {percentageInTune}%\")\n",
        "        print(f\"The piece is{' ' if isPieceInTune else ' not '}in tune.\\n\")"
      ],
      "metadata": {
        "id": "cdi-7Df0wAOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYzX62vECWx"
      },
      "source": [
        "# **Criteria 2 - Meter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMg1U7GQEIU4"
      },
      "source": [
        "**Running Beat Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testDirectoryMeter = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/\"\n",
        "\n",
        "# This function checks if a piece has randomly distributed notes.\n",
        "def hasRandomNotes(audioFile, maxStabilityThreshold = 0.07, maxNoteRepetitions = 5, maxNoteDistributionStability = 14):\n",
        "    audioData, sampleRate = librosa.load(audioFile)\n",
        "\n",
        "    cqt = librosa.cqt(y = audioData, sr = sampleRate) # Calculate the constant-Q chromagram [a representation of an audio signal that captures the energy distribution of different pitches over time].\n",
        "    chromagram = librosa.amplitude_to_db(np.abs(cqt), ref=np.max) # Convert to decibels for easier analysis.\n",
        "\n",
        "    # Calculating the note distribution stability\n",
        "    noteDistributionStability = np.std(chromagram, axis=0).mean()\n",
        "\n",
        "    onsetStrength = librosa.onset.onset_strength(y = audioData, sr = sampleRate) # Onset Strength: The magnitude of sudden changes in the audio signal [beginning of a note].\n",
        "    tempo, _ = librosa.beat.beat_track(onset_envelope = onsetStrength, sr = sampleRate)\n",
        "    _, beatTimes = librosa.beat.beat_track(onset_envelope = onsetStrength, sr = sampleRate, units = 'time') # Estimating the tempo and the beat times.\n",
        "\n",
        "    meanTempoInterval = np.mean(np.diff(beatTimes))\n",
        "    meanTempoIntervalStandardDeviation = np.std(np.diff(beatTimes))\n",
        "    rhythmicStability = meanTempoIntervalStandardDeviation / meanTempoInterval\n",
        "\n",
        "    noteOnsets = librosa.onset.onset_detect(y = audioData, sr = sampleRate) # Detects the beginning of notes and calculating the maximum note repetitions in the audio.\n",
        "    noteIntervals = np.diff(noteOnsets)\n",
        "    maxNoteReps = np.max(np.bincount(noteIntervals))\n",
        "\n",
        "    if rhythmicStability >= maxStabilityThreshold or noteDistributionStability >= maxNoteDistributionStability or maxNoteReps >= maxNoteRepitions:\n",
        "        return True, rhythmicStability, noteDistributionStability, maxNoteReps\n",
        "    else:\n",
        "        return False, rhythmicStability, noteDistributionStability, maxNoteReps\n",
        "\n",
        "for filename in os.listdir(testDirectoryMeter):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(monophonicDirectory, filename)\n",
        "        # filepathWAV = filepath[:-4] + '.wav'\n",
        "        # fs = FluidSynth()\n",
        "        # fs.midi_to_audio(filepath, filepath)\n",
        "        hasRandom, rhythmStability, noteDistributionStability, maxNoteRepitions = hasRandomNotes(filepath)\n",
        "        if hasRandom:\n",
        "            print(f\"{filename}: The piece has randomly distributed notes.\")\n",
        "        else:\n",
        "            print(f\"{filename}: The piece has a good rhythm with structured note distribution.\")\n",
        "        print(f\"Rhythmic Stability: {rhythmStability:.2f}\")                     # A lower value of rhythmic stability indicates more stable rhythm patterns | higher = less stable rhythm patterns.\n",
        "        print(f\"Note Distribution Stability: {noteDistributionStability:.2f}\")  # A lower value of note distribution stability indicates even distribution across the pitch range | higher = less even distribution\n",
        "        print(f\"Maximum Note Repititons: {maxNoteRepitions:.2f}\")"
      ],
      "metadata": {
        "id": "OcHGNe8DKDTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yeJchmmB4Kn"
      },
      "source": [
        "# **Criteria 3 - Melodic Structure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLwV6ckCY6B"
      },
      "source": [
        "**Running Melodic Structure Detection on Each Piece**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testDirectoryMelody = \"/content/drive/Shareddrives/neotyagi-dataset/maestro-v3.0.0/MaestroTest/[6] Melodic Structure Test\"\n",
        "\n",
        "# Function to analyze melodic structure\n",
        "def analyzeMelodicStructure(audioFile):\n",
        "    audioData, samplingRate = librosa.load(audioFile)\n",
        "\n",
        "    pitches, magnitudes = librosa.core.piptrack(y = audioData, sr = samplingRate) # Compute the pitch (fundamental frequency - lowest frequency) over time\n",
        "\n",
        "    pitchContour = pitches[np.argmax(magnitudes, axis=0)]\n",
        "    pitchContour = pitchContour.ravel()  # Flatten to a 1D Array.\n",
        "\n",
        "    melodicIntervals = np.diff(pitchContour)                                    # Melodic intervals are the differences between consecutive pitch values.\n",
        "    melodicPeaks, _ = find_peaks(pitchContour)\n",
        "    melodicComplexity = np.std(melodicIntervals)                                # Measures the standard deviation of the intervals between consecutive pitches in the melodic contour.\n",
        "\n",
        "\n",
        "    melodicStabilityRange = np.max(pitchContour) - np.min(pitchContour)         # Measures the span between the highest and lowest pitches in the melodic contour.\n",
        "    noteDurations = np.diff(melodicPeaks) / samplingRate\n",
        "    dynamicVariation = np.std(audioData)\n",
        "\n",
        "    return melodicPeaks, melodicComplexity, melodicStabilityRange, noteDurations, dynamicVariation\n",
        "\n",
        "for filename in os.listdir(testDirectoryMelody):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(testDirectoryMelody, filename)\n",
        "        melodicPeaks, melodicComplexity, melodicStabilityRange, noteDurations, dynamicVariation = analyzeMelodicStructure(filepath)  # Analyze melodic structure\n",
        "\n",
        "        print(f'File: {filename}\\n')\n",
        "\n",
        "        print(f'Melodic Peaks: {melodicPeaks}')                                 # Peaks in the pitch contour can indicate potential melodic peaks or points of repetition.\n",
        "\n",
        "\n",
        "        print(f'\\nMelodic Complexity: {melodicComplexity}')                     # A higher melodic complexity indicates greater variation in the intervals between consecutive pitches.\n",
        "                                                                                # This could suggest a more intricate and diverse melodic structure with complex patterns and variations.\n",
        "\n",
        "                                                                                # A lower melodic complexity suggests more consistent intervals between pitches.\n",
        "                                                                                # This could indicate a simpler or more repetitive melodic structure with less variation in pitch intervals.\n",
        "\n",
        "        print(f'\\nMelodic Stability: {melodicStabilityRange}')                  # A larger melodic stability range suggests a wider pitch range in the melody, indicating a more diverse or expansive melodic structure.\n",
        "                                                                                # A smaller melodic stability range suggests a more focused or narrow pitch range, possibly indicating a simpler or repetitive melodic structure.\n",
        "\n",
        "        print(f'\\nAverage Note Duration: {np.mean(noteDurations):.4f} seconds') # A higher average note duration indicates that the notes in the melody are sustained for a longer time. This might suggest a slower-paced melodic style.\n",
        "                                                                                # A lower average note duration suggests shorter note durations on average, which might indicate a faster-paced or more staccato melodic style.\n",
        "\n",
        "        print(f'\\nStandard Deviation of Note Duration: {np.std(noteDurations):.4f} seconds') # A higher standard deviation of note duration indicates greater variability in the duration of notes. This suggests a more dynamic melody.\n",
        "                                                                                # A lower standard deviation suggests more consistent note durations, indicating a more regular and predictable rhythm.\n",
        "\n",
        "        print(f'\\nDynamic Variation: {dynamicVariation}')                       # A higher dynamic variation suggests a wider range of loudness levels in the melody. This might indicate a more expressive and dynamically varied performance.\n",
        "                                                                                # A lower dynamic variation suggests a more consistent loudness level, which might indicate a more controlled or uniform performance.\n",
        "        print()\n",
        "        print('=' * 50)\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "cQaOkEo4CSBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}